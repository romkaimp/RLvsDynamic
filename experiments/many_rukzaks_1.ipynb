{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-25T10:38:30.957528Z",
     "start_time": "2025-11-25T10:38:30.945107Z"
    }
   },
   "source": [
    "from main.lstm_ae import train_model as lstm_train_model\n",
    "from main.policy import train_model as policy_gradient\n",
    "from models.default_model import decoder_model\n",
    "from models.LSTM_AE import LSTMAutoencoder\n",
    "from tasks.many_rukzaks import Task, DistributionType\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T10:38:31.026982Z",
     "start_time": "2025-11-25T10:38:31.014779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "params = {\n",
    "        'n':3,\n",
    "        'k':100,\n",
    "        'distrs':(DistributionType.UNIFORM, DistributionType.UNIFORM, DistributionType.UNIFORM),\n",
    "        'volume_params':{'a': 40, 'b': 60},\n",
    "        'cost_params':{'a': 15, 'b': 25},\n",
    "        'item_volume_params':{'a': 8, 'b': 12}\n",
    "}\n",
    "task = Task(**params)\n",
    "print(task)"
   ],
   "id": "fb62a32bae662be1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task(n=3, k=100)\n",
      "Рюкзаки: [44.24981921 45.01146004 45.86622999]\n",
      "Стоимости: [15.55635065 21.96662589 15.18771919 15.47746842 24.12846368 23.49165606\n",
      " 18.57142494 15.36464806 18.78717261 22.09674442 19.10834388 19.14590638\n",
      " 20.33415814 22.81532348 20.52064598 18.61837363 19.67060819 15.89826946\n",
      " 20.2248116  17.14693689 23.26091825 22.93226544 24.17831153 17.34256719\n",
      " 21.94211128 21.38788297 17.58436578 15.95708445 22.49160408 23.20252061\n",
      " 24.39197453 15.71403007 18.27775377 15.20402489 17.15833459 21.76495634\n",
      " 24.0659858  23.42753026 15.58650208 15.95778123 18.66880888 24.22368189\n",
      " 21.46433799 21.49640316 18.92183911 22.07439434 18.30338597 24.13815385\n",
      " 23.42923051 20.28968117 17.57092586 23.58343472 19.87016413 15.22272319\n",
      " 24.94738276 17.17096789 18.43580433 17.02826909 15.79026127 15.82635518\n",
      " 19.20058341 19.47447879 16.04392986 16.5581578  20.83699603 15.95556489\n",
      " 17.48573684 22.84859779 24.55338826 21.38794364 17.0314813  18.90356389\n",
      " 19.60457747 20.07362068 22.6012645  18.02284603 19.64198179 17.74832315\n",
      " 23.48108826 19.19153644 15.38637889 22.92808112 20.66305872 17.31286661\n",
      " 18.07521841 15.16655577 21.07177871 15.20355902 23.75590385 18.43780946\n",
      " 16.46069608 23.20455651 22.55448679 16.16732597 24.84574392 17.93162547\n",
      " 17.77627729 22.77824487 19.78906841 19.03601801]\n",
      "Размеры: [10.11702905  8.54714831  8.13146615 10.83502774  9.97630243  9.73284047\n",
      "  9.92752757 10.61216449  8.27668227 10.59881761  8.92715508 11.48153796\n",
      "  9.06369637  9.42136734 11.26644673  9.29428492 11.84695939  8.44884435\n",
      " 11.78309116 10.97908228  8.57106889 11.0953009   9.74905994  9.62183981\n",
      " 11.94591507  9.19115418 11.8621698  11.76355783 10.94240611  8.73266641\n",
      "  9.74878189 11.30342892  8.34833242 11.00921222  9.89367808  8.70632617\n",
      "  9.57487389  9.76395038 10.90054778 11.08374469  8.86780008  9.24951827\n",
      " 10.06192483  8.16634543  9.70647074  8.57197139  9.85366939  8.60630042\n",
      " 10.2922496   8.11139992  8.27625475 10.29905369  9.48816986  9.47455907\n",
      "  9.98169256  9.11046467 11.0694713   8.82147978  8.08823583 10.40539771\n",
      " 10.680588   11.63650346 10.81651249 11.08750388 10.63109801  9.07339436\n",
      "  9.66171597 10.08646383  8.16733354  8.02587311 10.08072084 11.5801129\n",
      " 11.97172498 10.65116547  9.0054329   8.39507574  8.84655286  9.39292578\n",
      "  9.41142658  9.31709091 11.31799264  8.32741111 11.89201742 10.98580781\n",
      " 11.11215792  9.44720306  8.98382001 10.92282651  9.16847307  8.33756352\n",
      "  8.43042178 10.94383689 11.26297255  8.16548092 10.87626638  8.56935362\n",
      "  8.3306099  11.17048118  9.13054958 11.85753745]\n",
      "Распределения: ['UNIFORM', 'UNIFORM', 'UNIFORM']\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Encoders training",
   "id": "7f5f5edb85439bf2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T10:38:31.189937Z",
     "start_time": "2025-11-25T10:38:31.101843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hidden_dim_lstm = 16\n",
    "encoder_models = [LSTMAutoencoder(input_dim=1, hidden_dim=hidden_dim_lstm) \n",
    "                  for _ in range(3)]\n",
    "optimizers = [torch.optim.Adam(encoder_models[i].parameters(), lr=0.01, eps=1e-8, weight_decay=0.001) for i in range(3)]\n",
    "criterion = nn.MSELoss()\n",
    "num_epochs = [512, 128, 256]\n",
    "batch_size = 32\n",
    "\n",
    "os.makedirs('encoder_models', exist_ok=True)\n",
    "\n",
    "for idx, object in enumerate(['r_volume', 'it_volume', 'it_cost']):\n",
    "    print(idx, \"model\")\n",
    "    model_path = f'encoder_models/encoder_{object}.pth'\n",
    "    if not os.path.exists(model_path):\n",
    "        encoder_models[idx], _ = lstm_train_model(\n",
    "            encoder_models[idx],\n",
    "            optimizers[idx],\n",
    "            criterion,\n",
    "            Task,\n",
    "            params,\n",
    "            num_epochs=num_epochs[idx],\n",
    "            batch_size=batch_size,\n",
    "            object=object,\n",
    "            verbose=True)\n",
    "\n",
    "        torch.save(encoder_models[idx].state_dict(), model_path)\n",
    "        print(f\"Модель {object} сохранена в {model_path}\")\n",
    "    else:\n",
    "        encoder_models[idx].load_state_dict(torch.load(model_path))\n",
    "        encoder_models[idx].eval()"
   ],
   "id": "a7d037b45e0754ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 model\n",
      "1 model\n",
      "2 model\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Decoders Training",
   "id": "9c918ef6ca4e1490"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T10:48:40.471733500Z",
     "start_time": "2025-11-25T10:48:34.898581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hidden_size = 32\n",
    "\n",
    "decoder1 = decoder_model(hidden_dim_lstm*3, hidden_size)\n",
    "decoder2 = decoder_model(hidden_dim_lstm*3 + 1, hidden_size)\n",
    "optimizer1 = torch.optim.Adam(decoder1.parameters(), lr=0.01, eps=1e-8, weight_decay=0.001)\n",
    "optimizer2 = torch.optim.Adam(decoder2.parameters(), lr=0.05, eps=1e-8, weight_decay=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "num_epochs = 16\n",
    "samples = 128\n",
    "decoder1, decoder2, losses, mean_ep_steps = policy_gradient(\n",
    "    decoder1,\n",
    "    decoder2,\n",
    "    optimizer1,\n",
    "    optimizer2,\n",
    "    Task,\n",
    "    params,\n",
    "    num_epochs=num_epochs, samples=samples, encoders=encoder_models,)\n",
    "\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()\n",
    "plt.plot(mean_ep_steps)\n",
    "plt.show()"
   ],
   "id": "ca48d6510fc701a8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 11\u001B[0m\n\u001B[0;32m      9\u001B[0m num_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m16\u001B[39m\n\u001B[0;32m     10\u001B[0m samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m128\u001B[39m\n\u001B[1;32m---> 11\u001B[0m decoder1, decoder2, losses, mean_ep_steps \u001B[38;5;241m=\u001B[39m \u001B[43mpolicy_gradient\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mTask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msamples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_models\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(losses)\n\u001B[0;32m     22\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[1;32m~\\PycharmProjects\\RLvsDynamic\\main\\policy.py:70\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model1, model2, optimizer1, optimizer2, Task, params, num_epochs, samples, encoders)\u001B[0m\n\u001B[0;32m     68\u001B[0m embeddings\u001B[38;5;241m.\u001B[39mappend(action)\n\u001B[0;32m     69\u001B[0m state2 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(embeddings, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 70\u001B[0m logits2 \u001B[38;5;241m=\u001B[39m \u001B[43mmodel2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     71\u001B[0m mask \u001B[38;5;241m=\u001B[39m (state[\u001B[38;5;241m0\u001B[39m][a1] \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m state[\u001B[38;5;241m1\u001B[39m])  \u001B[38;5;66;03m# [k]\u001B[39;00m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;66;03m#print(mask)\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\PycharmProjects\\RLvsDynamic\\models\\default_model.py:27\u001B[0m, in \u001B[0;36mdecoder_model.forward\u001B[1;34m(self, x, n)\u001B[0m\n\u001B[0;32m     25\u001B[0m     out, hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder(cur_x, hidden)\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;66;03m#print(\"dec_out shape:\", out.shape)# dec_out: (B, 1, hidden_size*2)\u001B[39;00m\n\u001B[1;32m---> 27\u001B[0m     out_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_layer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m     outputs\u001B[38;5;241m.\u001B[39mappend(out_step\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;66;03m# сохраняем (B,1)\u001B[39;00m\n\u001B[0;32m     30\u001B[0m \n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# outputs: list длины n, каждый элемент (B,1) -> склеим в (B, n, 1)\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Checking",
   "id": "73ffb88f8c728908"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T10:48:22.761110400Z",
     "start_time": "2025-11-25T10:18:07.671070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "task = Task(**params)\n",
    "greedy = task.solve_dynamically()\n",
    "cont = True\n",
    "\n",
    "decoder1.train()\n",
    "decoder2.train()\n",
    "while cont and task.not_end():\n",
    "    state = task.get_state()\n",
    "    n = state[0].shape[0]\n",
    "    k = state[1].shape[0]\n",
    "    embeddings = []\n",
    "    for idx, model in enumerate(encoder_models):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _, z = model.encode_zero(torch.from_numpy(state[idx]).to(torch.float32)[None, :, None])\n",
    "            embeddings.append(z)\n",
    "\n",
    "    #print(\"embs:\", embeddings[0].shape)\n",
    "    state1 = torch.cat(embeddings, dim=-1).unsqueeze(1)\n",
    "    #print(\"state1:\", state1.shape)                #print(\"n:\", n)\n",
    "    logits1 = decoder1(state1, n).squeeze(-1) # size:  - pi(a_1|s), pi(a_2|a_1, s)\n",
    "    #print(\"logits:\", logits1.shape)\n",
    "    dist1 = Categorical(logits=logits1)\n",
    "\n",
    "    a1 = dist1.sample()\n",
    "    #print(\"a:\", a1)\n",
    "    #print('st_a1:',state[0][a1] )\n",
    "    action = torch.tensor([state[0][a1]]).to(torch.float32)[:, None]\n",
    "    #print(\"action:\", action.shape)\n",
    "    embeddings.append(action)\n",
    "    state2 = torch.cat(embeddings, dim=-1).unsqueeze(1)\n",
    "    logits2 = decoder2(state2, k).squeeze(-1)\n",
    "    mask = (state[0][a1] >= state[1])  # [k]\n",
    "    #print(mask)\n",
    "    mask = np.reshape(mask, (1, -1))  # True там, где разрешено\n",
    "    mask = torch.tensor(mask, dtype=torch.bool)\n",
    "    masked_logits = logits2.clone()\n",
    "    masked_logits[~mask] = -1e9  # запрещённые позиции -> -inf\n",
    "\n",
    "    dist2 = Categorical(logits=masked_logits)\n",
    "\n",
    "    #dist2 = Categorical(logits=logits2)\n",
    "\n",
    "    a2 = dist2.sample()\n",
    "\n",
    "    cont = task.take_action(a1, a2)\n",
    "print(greedy, task.total_sum)"
   ],
   "id": "8880d5492fe98a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367.15601572979006 319.96547322542466\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T10:48:22.763349200Z",
     "start_time": "2025-11-25T10:18:08.769999Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9234e2e238f02065",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
